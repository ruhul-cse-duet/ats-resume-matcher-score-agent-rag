# local
DATABASE_URL=sqlite:///./ats.db
OLLAMA_URL=http://localhost:11434/api/generate
#docker
#DATABASE_URL=postgresql+psycopg2://ats_user:204085@db:5432/ats_db
#OLLAMA_URL=http://host.docker.internal:11434/api/generate

#Cloud (Railway / AWS)
#DATABASE_URL=postgresql+psycopg2://cloud_user:cloud_pass@cloud-host:5432/prod_db

JWT_SECRET=ruhul_204085_amin
#OLLAMA_MODEL=gemma2:2b
OLLAMA_MODEL=llama2:7b

OLLAMA_TIMEOUT=600
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================
# HuggingFace Configuration (REQUIRED)
# ============================================
# Get your token from: https://huggingface.co/settings/tokens
#HUGGINGFACE_API_KEY=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

# Alternative variable name (both work)
#HF_TOKEN=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

# ============================================
# HuggingFace Model Selection
# ============================================
# Choose one of these models:

# âš¡ FAST - Good for testing and development
# HUGGINGFACE_MODEL=google/flan-t5-large

# ðŸš€ VERY FAST - Lightweight, best for low resources
# HUGGINGFACE_MODEL=microsoft/phi-2

# ðŸ’Ž SMALLEST - Ultra lightweight for basic testing
HUGGINGFACE_MODEL=google/flan-t5-base

# ðŸ”¥ ADVANCED - Requires HuggingFace approval
# HUGGINGFACE_MODEL=meta-llama/Llama-2-7b-chat-hf

# ======================================================
# Local ollama Model
#OLLAMA_MODEL=ollama/llama2:7b

# ============================================
# Model Parameters
# ============================================
# Temperature: 0.0 = deterministic, 1.0 = creative
TEMPERATURE=0.7

# Maximum tokens in response
MAX_TOKENS=400

# ============================================
# Application Settings
# ============================================
MAX_FILE_SIZE_MB=10
ALLOWED_EXTENSIONS=.pdf,.docx,.txt
